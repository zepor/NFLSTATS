{
  "resolvedId": "/home/zepor/ssweb/frontend-container/node_modules/@apollo/client/core/QueryInfo.js",
  "transforms": [
    {
      "name": "vite:load-fallback",
      "result": "import { __assign } from \"tslib\";\nimport { equal } from \"@wry/equality\";\nimport { DeepMerger } from \"../utilities/index.js\";\nimport { mergeIncrementalData } from \"../utilities/index.js\";\nimport { reobserveCacheFirst } from \"./ObservableQuery.js\";\nimport { isNonEmptyArray, graphQLResultHasError, canUseWeakMap, } from \"../utilities/index.js\";\nimport { NetworkStatus, isNetworkRequestInFlight } from \"./networkStatus.js\";\nvar destructiveMethodCounts = new (canUseWeakMap ? WeakMap : Map)();\nfunction wrapDestructiveCacheMethod(cache, methodName) {\n    var original = cache[methodName];\n    if (typeof original === \"function\") {\n        cache[methodName] = function () {\n            destructiveMethodCounts.set(cache, \n            // The %1e15 allows the count to wrap around to 0 safely every\n            // quadrillion evictions, so there's no risk of overflow. To be\n            // clear, this is more of a pedantic principle than something\n            // that matters in any conceivable practical scenario.\n            (destructiveMethodCounts.get(cache) + 1) % 1e15);\n            // @ts-expect-error this is just too generic to be typed correctly\n            return original.apply(this, arguments);\n        };\n    }\n}\nfunction cancelNotifyTimeout(info) {\n    if (info[\"notifyTimeout\"]) {\n        clearTimeout(info[\"notifyTimeout\"]);\n        info[\"notifyTimeout\"] = void 0;\n    }\n}\n// A QueryInfo object represents a single query managed by the\n// QueryManager, which tracks all QueryInfo objects by queryId in its\n// this.queries Map. QueryInfo objects store the latest results and errors\n// for the given query, and are responsible for reporting those results to\n// the corresponding ObservableQuery, via the QueryInfo.notify method.\n// Results are reported asynchronously whenever setDiff marks the\n// QueryInfo object as dirty, though a call to the QueryManager's\n// broadcastQueries method may trigger the notification before it happens\n// automatically. This class used to be a simple interface type without\n// any field privacy or meaningful methods, which is why it still has so\n// many public fields. The effort to lock down and simplify the QueryInfo\n// interface is ongoing, and further improvements are welcome.\nvar QueryInfo = /** @class */ (function () {\n    function QueryInfo(queryManager, queryId) {\n        if (queryId === void 0) { queryId = queryManager.generateQueryId(); }\n        this.queryId = queryId;\n        this.listeners = new Set();\n        this.document = null;\n        this.lastRequestId = 1;\n        this.stopped = false;\n        this.dirty = false;\n        this.observableQuery = null;\n        var cache = (this.cache = queryManager.cache);\n        // Track how often cache.evict is called, since we want eviction to\n        // override the feud-stopping logic in the markResult method, by\n        // causing shouldWrite to return true. Wrapping the cache.evict method\n        // is a bit of a hack, but it saves us from having to make eviction\n        // counting an official part of the ApolloCache API.\n        if (!destructiveMethodCounts.has(cache)) {\n            destructiveMethodCounts.set(cache, 0);\n            wrapDestructiveCacheMethod(cache, \"evict\");\n            wrapDestructiveCacheMethod(cache, \"modify\");\n            wrapDestructiveCacheMethod(cache, \"reset\");\n        }\n    }\n    QueryInfo.prototype.init = function (query) {\n        var networkStatus = query.networkStatus || NetworkStatus.loading;\n        if (this.variables &&\n            this.networkStatus !== NetworkStatus.loading &&\n            !equal(this.variables, query.variables)) {\n            networkStatus = NetworkStatus.setVariables;\n        }\n        if (!equal(query.variables, this.variables)) {\n            this.lastDiff = void 0;\n        }\n        Object.assign(this, {\n            document: query.document,\n            variables: query.variables,\n            networkError: null,\n            graphQLErrors: this.graphQLErrors || [],\n            networkStatus: networkStatus,\n        });\n        if (query.observableQuery) {\n            this.setObservableQuery(query.observableQuery);\n        }\n        if (query.lastRequestId) {\n            this.lastRequestId = query.lastRequestId;\n        }\n        return this;\n    };\n    QueryInfo.prototype.reset = function () {\n        cancelNotifyTimeout(this);\n        this.dirty = false;\n    };\n    QueryInfo.prototype.getDiff = function () {\n        var options = this.getDiffOptions();\n        if (this.lastDiff && equal(options, this.lastDiff.options)) {\n            return this.lastDiff.diff;\n        }\n        this.updateWatch(this.variables);\n        var oq = this.observableQuery;\n        if (oq && oq.options.fetchPolicy === \"no-cache\") {\n            return { complete: false };\n        }\n        var diff = this.cache.diff(options);\n        this.updateLastDiff(diff, options);\n        return diff;\n    };\n    QueryInfo.prototype.updateLastDiff = function (diff, options) {\n        this.lastDiff =\n            diff ?\n                {\n                    diff: diff,\n                    options: options || this.getDiffOptions(),\n                }\n                : void 0;\n    };\n    QueryInfo.prototype.getDiffOptions = function (variables) {\n        var _a;\n        if (variables === void 0) { variables = this.variables; }\n        return {\n            query: this.document,\n            variables: variables,\n            returnPartialData: true,\n            optimistic: true,\n            canonizeResults: (_a = this.observableQuery) === null || _a === void 0 ? void 0 : _a.options.canonizeResults,\n        };\n    };\n    QueryInfo.prototype.setDiff = function (diff) {\n        var _this = this;\n        var oldDiff = this.lastDiff && this.lastDiff.diff;\n        this.updateLastDiff(diff);\n        if (!this.dirty && !equal(oldDiff && oldDiff.result, diff && diff.result)) {\n            this.dirty = true;\n            if (!this.notifyTimeout) {\n                this.notifyTimeout = setTimeout(function () { return _this.notify(); }, 0);\n            }\n        }\n    };\n    QueryInfo.prototype.setObservableQuery = function (oq) {\n        var _this = this;\n        if (oq === this.observableQuery)\n            return;\n        if (this.oqListener) {\n            this.listeners.delete(this.oqListener);\n        }\n        this.observableQuery = oq;\n        if (oq) {\n            oq[\"queryInfo\"] = this;\n            this.listeners.add((this.oqListener = function () {\n                var diff = _this.getDiff();\n                if (diff.fromOptimisticTransaction) {\n                    // If this diff came from an optimistic transaction, deliver the\n                    // current cache data to the ObservableQuery, but don't perform a\n                    // reobservation, since oq.reobserveCacheFirst might make a network\n                    // request, and we never want to trigger network requests in the\n                    // middle of optimistic updates.\n                    oq[\"observe\"]();\n                }\n                else {\n                    // Otherwise, make the ObservableQuery \"reobserve\" the latest data\n                    // using a temporary fetch policy of \"cache-first\", so complete cache\n                    // results have a chance to be delivered without triggering additional\n                    // network requests, even when options.fetchPolicy is \"network-only\"\n                    // or \"cache-and-network\". All other fetch policies are preserved by\n                    // this method, and are handled by calling oq.reobserve(). If this\n                    // reobservation is spurious, isDifferentFromLastResult still has a\n                    // chance to catch it before delivery to ObservableQuery subscribers.\n                    reobserveCacheFirst(oq);\n                }\n            }));\n        }\n        else {\n            delete this.oqListener;\n        }\n    };\n    QueryInfo.prototype.notify = function () {\n        var _this = this;\n        cancelNotifyTimeout(this);\n        if (this.shouldNotify()) {\n            this.listeners.forEach(function (listener) { return listener(_this); });\n        }\n        this.dirty = false;\n    };\n    QueryInfo.prototype.shouldNotify = function () {\n        if (!this.dirty || !this.listeners.size) {\n            return false;\n        }\n        if (isNetworkRequestInFlight(this.networkStatus) && this.observableQuery) {\n            var fetchPolicy = this.observableQuery.options.fetchPolicy;\n            if (fetchPolicy !== \"cache-only\" && fetchPolicy !== \"cache-and-network\") {\n                return false;\n            }\n        }\n        return true;\n    };\n    QueryInfo.prototype.stop = function () {\n        if (!this.stopped) {\n            this.stopped = true;\n            // Cancel the pending notify timeout\n            this.reset();\n            this.cancel();\n            // Revert back to the no-op version of cancel inherited from\n            // QueryInfo.prototype.\n            this.cancel = QueryInfo.prototype.cancel;\n            var oq = this.observableQuery;\n            if (oq)\n                oq.stopPolling();\n        }\n    };\n    // This method is a no-op by default, until/unless overridden by the\n    // updateWatch method.\n    QueryInfo.prototype.cancel = function () { };\n    QueryInfo.prototype.updateWatch = function (variables) {\n        var _this = this;\n        if (variables === void 0) { variables = this.variables; }\n        var oq = this.observableQuery;\n        if (oq && oq.options.fetchPolicy === \"no-cache\") {\n            return;\n        }\n        var watchOptions = __assign(__assign({}, this.getDiffOptions(variables)), { watcher: this, callback: function (diff) { return _this.setDiff(diff); } });\n        if (!this.lastWatch || !equal(watchOptions, this.lastWatch)) {\n            this.cancel();\n            this.cancel = this.cache.watch((this.lastWatch = watchOptions));\n        }\n    };\n    QueryInfo.prototype.resetLastWrite = function () {\n        this.lastWrite = void 0;\n    };\n    QueryInfo.prototype.shouldWrite = function (result, variables) {\n        var lastWrite = this.lastWrite;\n        return !(lastWrite &&\n            // If cache.evict has been called since the last time we wrote this\n            // data into the cache, there's a chance writing this result into\n            // the cache will repair what was evicted.\n            lastWrite.dmCount === destructiveMethodCounts.get(this.cache) &&\n            equal(variables, lastWrite.variables) &&\n            equal(result.data, lastWrite.result.data));\n    };\n    QueryInfo.prototype.markResult = function (result, document, options, cacheWriteBehavior) {\n        var _this = this;\n        var merger = new DeepMerger();\n        var graphQLErrors = isNonEmptyArray(result.errors) ? result.errors.slice(0) : [];\n        // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n        // requests. To allow future notify timeouts, diff and dirty are reset as well.\n        this.reset();\n        if (\"incremental\" in result && isNonEmptyArray(result.incremental)) {\n            var mergedData = mergeIncrementalData(this.getDiff().result, result);\n            result.data = mergedData;\n            // Detect the first chunk of a deferred query and merge it with existing\n            // cache data. This ensures a `cache-first` fetch policy that returns\n            // partial cache data or a `cache-and-network` fetch policy that already\n            // has full data in the cache does not complain when trying to merge the\n            // initial deferred server data with existing cache data.\n        }\n        else if (\"hasNext\" in result && result.hasNext) {\n            var diff = this.getDiff();\n            result.data = merger.merge(diff.result, result.data);\n        }\n        this.graphQLErrors = graphQLErrors;\n        if (options.fetchPolicy === \"no-cache\") {\n            this.updateLastDiff({ result: result.data, complete: true }, this.getDiffOptions(options.variables));\n        }\n        else if (cacheWriteBehavior !== 0 /* CacheWriteBehavior.FORBID */) {\n            if (shouldWriteResult(result, options.errorPolicy)) {\n                // Using a transaction here so we have a chance to read the result\n                // back from the cache before the watch callback fires as a result\n                // of writeQuery, so we can store the new diff quietly and ignore\n                // it when we receive it redundantly from the watch callback.\n                this.cache.performTransaction(function (cache) {\n                    if (_this.shouldWrite(result, options.variables)) {\n                        cache.writeQuery({\n                            query: document,\n                            data: result.data,\n                            variables: options.variables,\n                            overwrite: cacheWriteBehavior === 1 /* CacheWriteBehavior.OVERWRITE */,\n                        });\n                        _this.lastWrite = {\n                            result: result,\n                            variables: options.variables,\n                            dmCount: destructiveMethodCounts.get(_this.cache),\n                        };\n                    }\n                    else {\n                        // If result is the same as the last result we received from\n                        // the network (and the variables match too), avoid writing\n                        // result into the cache again. The wisdom of skipping this\n                        // cache write is far from obvious, since any cache write\n                        // could be the one that puts the cache back into a desired\n                        // state, fixing corruption or missing data. However, if we\n                        // always write every network result into the cache, we enable\n                        // feuds between queries competing to update the same data in\n                        // incompatible ways, which can lead to an endless cycle of\n                        // cache broadcasts and useless network requests. As with any\n                        // feud, eventually one side must step back from the brink,\n                        // letting the other side(s) have the last word(s). There may\n                        // be other points where we could break this cycle, such as\n                        // silencing the broadcast for cache.writeQuery (not a good\n                        // idea, since it just delays the feud a bit) or somehow\n                        // avoiding the network request that just happened (also bad,\n                        // because the server could return useful new data). All\n                        // options considered, skipping this cache write seems to be\n                        // the least damaging place to break the cycle, because it\n                        // reflects the intuition that we recently wrote this exact\n                        // result into the cache, so the cache *should* already/still\n                        // contain this data. If some other query has clobbered that\n                        // data in the meantime, that's too bad, but there will be no\n                        // winners if every query blindly reverts to its own version\n                        // of the data. This approach also gives the network a chance\n                        // to return new data, which will be written into the cache as\n                        // usual, notifying only those queries that are directly\n                        // affected by the cache updates, as usual. In the future, an\n                        // even more sophisticated cache could perhaps prevent or\n                        // mitigate the clobbering somehow, but that would make this\n                        // particular cache write even less important, and thus\n                        // skipping it would be even safer than it is today.\n                        if (_this.lastDiff && _this.lastDiff.diff.complete) {\n                            // Reuse data from the last good (complete) diff that we\n                            // received, when possible.\n                            result.data = _this.lastDiff.diff.result;\n                            return;\n                        }\n                        // If the previous this.diff was incomplete, fall through to\n                        // re-reading the latest data with cache.diff, below.\n                    }\n                    var diffOptions = _this.getDiffOptions(options.variables);\n                    var diff = cache.diff(diffOptions);\n                    // In case the QueryManager stops this QueryInfo before its\n                    // results are delivered, it's important to avoid restarting the\n                    // cache watch when markResult is called. We also avoid updating\n                    // the watch if we are writing a result that doesn't match the current\n                    // variables to avoid race conditions from broadcasting the wrong\n                    // result.\n                    if (!_this.stopped && equal(_this.variables, options.variables)) {\n                        // Any time we're about to update this.diff, we need to make\n                        // sure we've started watching the cache.\n                        _this.updateWatch(options.variables);\n                    }\n                    // If we're allowed to write to the cache, and we can read a\n                    // complete result from the cache, update result.data to be the\n                    // result from the cache, rather than the raw network result.\n                    // Set without setDiff to avoid triggering a notify call, since\n                    // we have other ways of notifying for this result.\n                    _this.updateLastDiff(diff, diffOptions);\n                    if (diff.complete) {\n                        result.data = diff.result;\n                    }\n                });\n            }\n            else {\n                this.lastWrite = void 0;\n            }\n        }\n    };\n    QueryInfo.prototype.markReady = function () {\n        this.networkError = null;\n        return (this.networkStatus = NetworkStatus.ready);\n    };\n    QueryInfo.prototype.markError = function (error) {\n        this.networkStatus = NetworkStatus.error;\n        this.lastWrite = void 0;\n        this.reset();\n        if (error.graphQLErrors) {\n            this.graphQLErrors = error.graphQLErrors;\n        }\n        if (error.networkError) {\n            this.networkError = error.networkError;\n        }\n        return error;\n    };\n    return QueryInfo;\n}());\nexport { QueryInfo };\nexport function shouldWriteResult(result, errorPolicy) {\n    if (errorPolicy === void 0) { errorPolicy = \"none\"; }\n    var ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n    var writeWithErrors = !graphQLResultHasError(result);\n    if (!writeWithErrors && ignoreErrors && result.data) {\n        writeWithErrors = true;\n    }\n    return writeWithErrors;\n}\n//# sourceMappingURL=QueryInfo.js.map",
      "start": 1702937441854,
      "end": 1702937441887,
      "sourcemaps": null
    },
    {
      "name": "vite:react-babel",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "pre"
    },
    {
      "name": "vite:css",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:esbuild",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:json",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:worker",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:define",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:css-post",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:build-html",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:worker-import-meta-url",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "vite:asset-import-meta-url",
      "start": 1702937441887,
      "end": 1702937441887,
      "order": "normal"
    },
    {
      "name": "commonjs",
      "start": 1702937441887,
      "end": 1702937441888,
      "order": "normal"
    },
    {
      "name": "inject",
      "start": 1702937441888,
      "end": 1702937441888,
      "order": "normal"
    },
    {
      "name": "vite:dynamic-import-vars",
      "start": 1702937441888,
      "end": 1702937441888,
      "order": "normal"
    },
    {
      "name": "vite:import-glob",
      "start": 1702937441888,
      "end": 1702937441888,
      "order": "normal"
    },
    {
      "name": "vite:build-import-analysis",
      "start": 1702937441888,
      "end": 1702937441888,
      "order": "normal"
    },
    {
      "name": "vite:reporter",
      "start": 1702937441888,
      "end": 1702937441888,
      "order": "normal"
    }
  ]
}
