<extensionManifest><groupId>org.apache.nifi</groupId><artifactId>nifi-parquet-nar</artifactId><version>2.0.0-SNAPSHOT</version><parentNar><groupId>org.apache.nifi</groupId><artifactId>nifi-hadoop-libraries-nar</artifactId><version>2.0.0-SNAPSHOT</version></parentNar><systemApiVersion>2.0.0-SNAPSHOT</systemApiVersion><buildInfo><tag>HEAD</tag><branch>main</branch><revision>f352857</revision></buildInfo><extensions><extension><name>org.apache.nifi.processors.parquet.ConvertAvroToParquet</name><type>PROCESSOR</type><description>Converts Avro records into Parquet file format. The incoming FlowFile should be a valid avro file. If an incoming FlowFile does not contain any records, an empty parquet file is the output. NOTE: Many Avro datatypes (collections, primitives, and unions of primitives, e.g.) can be converted to parquet, but unions of collections and other complex datatypes may not be able to be converted to Parquet.</description><tags><tag>avro</tag><tag>parquet</tag><tag>convert</tag></tags><properties><property><name>compression-type</name><displayName>Compression Type</displayName><description>The type of compression for the file being written.</description><defaultValue>UNCOMPRESSED</defaultValue><allowableValues><allowableValue><displayName>UNCOMPRESSED</displayName><value>UNCOMPRESSED</value><description></description></allowableValue><allowableValue><displayName>SNAPPY</displayName><value>SNAPPY</value><description></description></allowableValue><allowableValue><displayName>GZIP</displayName><value>GZIP</value><description></description></allowableValue><allowableValue><displayName>LZO</displayName><value>LZO</value><description></description></allowableValue><allowableValue><displayName>BROTLI</displayName><value>BROTLI</value><description></description></allowableValue><allowableValue><displayName>LZ4</displayName><value>LZ4</value><description></description></allowableValue><allowableValue><displayName>ZSTD</displayName><value>ZSTD</value><description></description></allowableValue><allowableValue><displayName>LZ4_RAW</displayName><value>LZ4_RAW</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>row-group-size</name><displayName>Row Group Size</displayName><description>The row group size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>page-size</name><displayName>Page Size</displayName><description>The page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dictionary-page-size</name><displayName>Dictionary Page Size</displayName><description>The dictionary page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-padding-size</name><displayName>Max Padding Size</displayName><description>The maximum amount of padding that will be used to align row groups with blocks in the underlying filesystem. If the underlying filesystem is not a block filesystem like HDFS, this has no effect. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>enable-dictionary-encoding</name><displayName>Enable Dictionary Encoding</displayName><description>Specifies whether dictionary encoding should be enabled for the Parquet writer</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>enable-validation</name><displayName>Enable Validation</displayName><description>Specifies whether validation should be enabled for the Parquet writer</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>writer-version</name><displayName>Writer Version</displayName><description>Specifies the version used by Parquet writer</description><allowableValues><allowableValue><displayName>PARQUET_1_0</displayName><value>PARQUET_1_0</value><description></description></allowableValue><allowableValue><displayName>PARQUET_2_0</displayName><value>PARQUET_2_0</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>success</name><description>Parquet file that was converted successfully from Avro</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>Avro content that could not be processed</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>filename</name><description>Sets the filename to the existing filename with the extension replaced by / added to by .parquet</description></writesAttribute><writesAttribute><name>record.count</name><description>Sets the number of records in the parquet file.</description></writesAttribute></writesAttributes><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.processors.parquet.FetchParquet</name><type>PROCESSOR</type><description>Reads from a given Parquet file and writes records to the content of the flow file using the selected record writer. The original Parquet file will remain unchanged, and the content of the flow file will be replaced with records of the selected type. This processor can be used with ListHDFS or ListFile to obtain a listing of files to fetch.</description><tags><tag>parquet</tag><tag>hadoop</tag><tag>HDFS</tag><tag>get</tag><tag>ingest</tag><tag>fetch</tag><tag>source</tag><tag>record</tag></tags><properties><property><name>Hadoop Configuration Resources</name><displayName>Hadoop Configuration Resources</displayName><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration. To use swebhdfs, see 'Additional Details' section of PutHDFS's documentation.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>MULTIPLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>kerberos-credentials-service</name><displayName>Kerberos Credentials Service</displayName><description>Specifies the Kerberos Credentials Controller Service that should be used for authenticating with Kerberos</description><controllerServiceDefinition><className>org.apache.nifi.kerberos.KerberosCredentialsService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>kerberos-user-service</name><displayName>Kerberos User Service</displayName><description>Specifies the Kerberos User Controller Service that should be used for authenticating with Kerberos</description><controllerServiceDefinition><className>org.apache.nifi.kerberos.KerberosUserService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Kerberos Principal</name><displayName>Kerberos Principal</displayName><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Kerberos Keytab</name><displayName>Kerberos Keytab</displayName><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Kerberos Password</name><displayName>Kerberos Password</displayName><description>Kerberos password associated with the principal.</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Kerberos Relogin Period</name><displayName>Kerberos Relogin Period</displayName><description>Period of time which should pass before attempting a kerberos relogin.

This property has been deprecated, and has no effect on processing. Relogins now occur automatically.</description><defaultValue>4 hours</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Additional Classpath Resources</name><displayName>Additional Classpath Resources</displayName><description>A comma-separated list of paths to files and/or directories that will be added to the classpath and used for loading native libraries. When specifying a directory, all files with in the directory will be added to the classpath, but further sub-directories will not be included.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>true</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>MULTIPLE</cardinality><resourceTypes><resourceType>DIRECTORY</resourceType><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>filename</name><displayName>Filename</displayName><description>The name of the file to retrieve</description><defaultValue>${path}/${filename}</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>record-writer</name><displayName>Record Writer</displayName><description>The service for writing records to the FlowFile content</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>retry</name><description>FlowFiles will be routed to this relationship if the content of the file cannot be retrieved, but might be able to be in the future if tried again. This generally indicates that the Fetch should be tried again.</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>FlowFiles will be routed to this relationship once they have been updated with the content of the file</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>FlowFiles will be routed to this relationship if the content of the file cannot be retrieved and trying again will likely not be helpful. This would occur, for instance, if the file is not found or if there is a permissions issue</description><autoTerminated>false</autoTerminated></relationship></relationships><writesAttributes><writesAttribute><name>fetch.failure.reason</name><description>When a FlowFile is routed to 'failure', this attribute is added indicating why the file could not be fetched from the given filesystem.</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records in the resulting flow file</description></writesAttribute><writesAttribute><name>hadoop.file.url</name><description>The hadoop url for the file is stored in this attribute.</description></writesAttribute></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><supportsBatching>true</supportsBatching><defaultSettings><yieldDuration>100 ms</yieldDuration><penaltyDuration>30 sec</penaltyDuration><bulletinLevel>WARN</bulletinLevel></defaultSettings><restricted><restrictions><restriction><requiredPermission>read distributed filesystem</requiredPermission><explanation>Provides operator the ability to retrieve any file that NiFi has access to in HDFS or the local filesystem.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement><seeAlso><see>org.apache.nifi.processors.parquet.PutParquet</see></seeAlso></extension><extension><name>org.apache.nifi.processors.parquet.PutParquet</name><type>PROCESSOR</type><description>Reads records from an incoming FlowFile using the provided Record Reader, and writes those records to a Parquet file. The schema for the Parquet file must be provided in the processor properties. This processor will first write a temporary dot file and upon successfully writing every record to the dot file, it will rename the dot file to it's final name. If the dot file cannot be renamed, the rename operation will be attempted up to 10 times, and if still not successful, the dot file will be deleted and the flow file will be routed to failure.  If any error occurs while reading records from the input, or writing records to the output, the entire dot file will be removed and the flow file will be routed to failure or retry, depending on the error.</description><tags><tag>put</tag><tag>parquet</tag><tag>hadoop</tag><tag>HDFS</tag><tag>filesystem</tag><tag>record</tag></tags><properties><property><name>Hadoop Configuration Resources</name><displayName>Hadoop Configuration Resources</displayName><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration. To use swebhdfs, see 'Additional Details' section of PutHDFS's documentation.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>MULTIPLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>kerberos-credentials-service</name><displayName>Kerberos Credentials Service</displayName><description>Specifies the Kerberos Credentials Controller Service that should be used for authenticating with Kerberos</description><controllerServiceDefinition><className>org.apache.nifi.kerberos.KerberosCredentialsService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>kerberos-user-service</name><displayName>Kerberos User Service</displayName><description>Specifies the Kerberos User Controller Service that should be used for authenticating with Kerberos</description><controllerServiceDefinition><className>org.apache.nifi.kerberos.KerberosUserService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Kerberos Principal</name><displayName>Kerberos Principal</displayName><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Kerberos Keytab</name><displayName>Kerberos Keytab</displayName><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>SINGLE</cardinality><resourceTypes><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>Kerberos Password</name><displayName>Kerberos Password</displayName><description>Kerberos password associated with the principal.</description><required>false</required><sensitive>true</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Kerberos Relogin Period</name><displayName>Kerberos Relogin Period</displayName><description>Period of time which should pass before attempting a kerberos relogin.

This property has been deprecated, and has no effect on processing. Relogins now occur automatically.</description><defaultValue>4 hours</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>ENVIRONMENT</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Additional Classpath Resources</name><displayName>Additional Classpath Resources</displayName><description>A comma-separated list of paths to files and/or directories that will be added to the classpath and used for loading native libraries. When specifying a directory, all files with in the directory will be added to the classpath, but further sub-directories will not be included.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>true</dynamicallyModifiesClasspath><dynamic>false</dynamic><resourceDefinition><cardinality>MULTIPLE</cardinality><resourceTypes><resourceType>DIRECTORY</resourceType><resourceType>FILE</resourceType></resourceTypes></resourceDefinition></property><property><name>record-reader</name><displayName>Record Reader</displayName><description>The service for reading records from incoming flow files.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>Directory</name><displayName>Directory</displayName><description>The parent directory to which files should be written. Will be created if it doesn't exist.</description><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>compression-type</name><displayName>Compression Type</displayName><description>The type of compression for the file being written.</description><defaultValue>UNCOMPRESSED</defaultValue><allowableValues><allowableValue><displayName>UNCOMPRESSED</displayName><value>UNCOMPRESSED</value><description></description></allowableValue><allowableValue><displayName>SNAPPY</displayName><value>SNAPPY</value><description></description></allowableValue><allowableValue><displayName>GZIP</displayName><value>GZIP</value><description></description></allowableValue><allowableValue><displayName>LZO</displayName><value>LZO</value><description></description></allowableValue><allowableValue><displayName>BROTLI</displayName><value>BROTLI</value><description></description></allowableValue><allowableValue><displayName>LZ4</displayName><value>LZ4</value><description></description></allowableValue><allowableValue><displayName>ZSTD</displayName><value>ZSTD</value><description></description></allowableValue><allowableValue><displayName>LZ4_RAW</displayName><value>LZ4_RAW</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>overwrite</name><displayName>Overwrite Files</displayName><description>Whether or not to overwrite existing files in the same directory with the same name. When set to false, flow files will be routed to failure when a file exists in the same directory with the same name.</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>permissions-umask</name><displayName>Permissions umask</displayName><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>remote-group</name><displayName>Remote Group</displayName><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>remote-owner</name><displayName>Remote Owner</displayName><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>row-group-size</name><displayName>Row Group Size</displayName><description>The row group size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>page-size</name><displayName>Page Size</displayName><description>The page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dictionary-page-size</name><displayName>Dictionary Page Size</displayName><description>The dictionary page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-padding-size</name><displayName>Max Padding Size</displayName><description>The maximum amount of padding that will be used to align row groups with blocks in the underlying filesystem. If the underlying filesystem is not a block filesystem like HDFS, this has no effect. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>enable-dictionary-encoding</name><displayName>Enable Dictionary Encoding</displayName><description>Specifies whether dictionary encoding should be enabled for the Parquet writer</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>enable-validation</name><displayName>Enable Validation</displayName><description>Specifies whether validation should be enabled for the Parquet writer</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>writer-version</name><displayName>Writer Version</displayName><description>Specifies the version used by Parquet writer</description><allowableValues><allowableValue><displayName>PARQUET_1_0</displayName><value>PARQUET_1_0</value><description></description></allowableValue><allowableValue><displayName>PARQUET_2_0</displayName><value>PARQUET_2_0</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>avro-write-old-list-structure</name><displayName>Avro Write Old List Structure</displayName><description>Specifies the value for 'parquet.avro.write-old-list-structure' in the underlying Parquet library</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>avro-add-list-element-records</name><displayName>Avro Add List Element Records</displayName><description>Specifies the value for 'parquet.avro.add-list-element-records' in the underlying Parquet library</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>remove-crc-files</name><displayName>Remove CRC Files</displayName><description>Specifies whether the corresponding CRC file should be deleted upon successfully writing a Parquet file</description><defaultValue>false</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><relationships><relationship><name>retry</name><description>Flow Files that could not be processed due to issues that can be retried are transferred to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>success</name><description>Flow Files that have been successfully processed are transferred to this relationship</description><autoTerminated>false</autoTerminated></relationship><relationship><name>failure</name><description>Flow Files that could not be processed due to issue that cannot be retried are transferred to this relationship</description><autoTerminated>false</autoTerminated></relationship></relationships><readsAttributes><readsAttribute><name>filename</name><description>The name of the file to write comes from the value of this attribute.</description></readsAttribute></readsAttributes><writesAttributes><writesAttribute><name>filename</name><description>The name of the file is stored in this attribute.</description></writesAttribute><writesAttribute><name>absolute.hdfs.path</name><description>The absolute path to the file is stored in this attribute.</description></writesAttribute><writesAttribute><name>hadoop.file.url</name><description>The hadoop url for the file is stored in this attribute.</description></writesAttribute><writesAttribute><name>record.count</name><description>The number of records written to the Parquet file</description></writesAttribute></writesAttributes><triggerWhenEmpty>true</triggerWhenEmpty><defaultSettings><yieldDuration>100 ms</yieldDuration><penaltyDuration>30 sec</penaltyDuration><bulletinLevel>WARN</bulletinLevel></defaultSettings><restricted><restrictions><restriction><requiredPermission>write distributed filesystem</requiredPermission><explanation>Provides operator the ability to write any file that NiFi has access to in HDFS or the local filesystem.</explanation></restriction></restrictions></restricted><inputRequirement>INPUT_REQUIRED</inputRequirement></extension><extension><name>org.apache.nifi.parquet.ParquetReader</name><type>CONTROLLER_SERVICE</type><description>Parses Parquet data and returns each Parquet record as a separate Record object. The schema will come from the Parquet data itself.</description><tags><tag>parquet</tag><tag>parse</tag><tag>record</tag><tag>row</tag><tag>reader</tag></tags><properties><property><name>avro-read-compatibility</name><displayName>Avro Read Compatibility</displayName><description>Specifies the value for 'parquet.avro.compatible' in the underlying Parquet library</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><providedServiceAPIs><providedServiceAPI><className>org.apache.nifi.serialization.RecordReaderFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></providedServiceAPI></providedServiceAPIs></extension><extension><name>org.apache.nifi.parquet.ParquetRecordSetWriter</name><type>CONTROLLER_SERVICE</type><description>Writes the contents of a RecordSet in Parquet format.</description><tags><tag>parquet</tag><tag>result</tag><tag>set</tag><tag>writer</tag><tag>serializer</tag><tag>record</tag><tag>recordset</tag><tag>row</tag></tags><properties><property><name>Schema Write Strategy</name><displayName>Schema Write Strategy</displayName><description>Specifies how the schema for a Record should be added to the data.</description><defaultValue>no-schema</defaultValue><allowableValues><allowableValue><displayName>Do Not Write Schema</displayName><value>no-schema</value><description>Do not add any schema-related information to the FlowFile.</description></allowableValue><allowableValue><displayName>Set 'schema.name' Attribute</displayName><value>schema-name</value><description>The FlowFile will be given an attribute named 'schema.name' and this attribute will indicate the name of the schema in the Schema Registry. Note that ifthe schema for a record is not obtained from a Schema Registry, then no attribute will be added.</description></allowableValue><allowableValue><displayName>Set 'avro.schema' Attribute</displayName><value>full-schema-attribute</value><description>The FlowFile will be given an attribute named 'avro.schema' and this attribute will contain the Avro Schema that describes the records in the FlowFile. The contents of the FlowFile need not be Avro, but the text of the schema will be used.</description></allowableValue><allowableValue><displayName>HWX Schema Reference Attributes</displayName><value>hwx-schema-ref-attributes</value><description>The FlowFile will be given a set of 3 attributes to describe the schema: 'schema.identifier', 'schema.version', and 'schema.protocol.version'. Note that if the schema for a record does not contain the necessary identifier and version, an Exception will be thrown when attempting to write the data.</description></allowableValue><allowableValue><displayName>HWX Content-Encoded Schema Reference</displayName><value>hwx-content-encoded-schema</value><description>The content of the FlowFile will contain a reference to a schema in the Schema Registry service. The reference is encoded as a single byte indicating the 'protocol version', followed by 8 bytes indicating the schema identifier, and finally 4 bytes indicating the schema version, as per the Hortonworks Schema Registry serializers and deserializers, as found at https://github.com/hortonworks/registry. This will be prepended to each FlowFile. Note that if the schema for a record does not contain the necessary identifier and version, an Exception will be thrown when attempting to write the data.</description></allowableValue><allowableValue><displayName>Confluent Schema Registry Reference</displayName><value>confluent-encoded</value><description>The content of the FlowFile will contain a reference to a schema in the Schema Registry service. The reference is encoded as a single 'Magic Byte' followed by 4 bytes representing the identifier of the schema, as outlined at http://docs.confluent.io/current/schema-registry/docs/serializer-formatter.html. This will be prepended to each FlowFile. Note that if the schema for a record does not contain the necessary identifier and version, an Exception will be thrown when attempting to write the data. This is based on the encoding used by version 3.2.x of the Confluent Schema Registry.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>schema-cache</name><displayName>Schema Cache</displayName><description>Specifies a Schema Cache to add the Record Schema to so that Record Readers can quickly lookup the schema.</description><controllerServiceDefinition><className>org.apache.nifi.serialization.RecordSchemaCacheService</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>schema-protocol-version</name><displayName>Schema Protocol Version</displayName><description>The protocol version to be used for Schema Write Strategies that require a protocol version, such as Hortonworks Schema Registry strategies. Valid protocol versions for Hortonworks Schema Registry are integer values 1, 2, or 3.</description><defaultValue>1</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>Schema Write Strategy</propertyName><propertyDisplayName>Schema Write Strategy</propertyDisplayName><dependentValues><dependentValue>hwx-schema-ref-attributes</dependentValue><dependentValue>hwx-content-encoded-schema</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-access-strategy</name><displayName>Schema Access Strategy</displayName><description>Specifies how to obtain the schema that is to be used for interpreting the data.</description><defaultValue>inherit-record-schema</defaultValue><allowableValues><allowableValue><displayName>Inherit Record Schema</displayName><value>inherit-record-schema</value><description>The schema used to write records will be the same schema that was given to the Record when the Record was created.</description></allowableValue><allowableValue><displayName>Use 'Schema Name' Property</displayName><value>schema-name</value><description>The name of the Schema to use is specified by the 'Schema Name' Property. The value of this property is used to lookup the Schema in the configured Schema Registry service.</description></allowableValue><allowableValue><displayName>Use 'Schema Text' Property</displayName><value>schema-text-property</value><description>The text of the Schema itself is specified by the 'Schema Text' Property. The value of this property must be a valid Avro Schema. If Expression Language is used, the value of the 'Schema Text' property must be valid after substituting the expressions.</description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>schema-registry</name><displayName>Schema Registry</displayName><description>Specifies the Controller Service to use for the Schema Registry</description><controllerServiceDefinition><className>org.apache.nifi.schemaregistry.services.SchemaRegistry</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></controllerServiceDefinition><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>confluent-encoded</dependentValue><dependentValue>schema-name</dependentValue><dependentValue>hwx-schema-ref-attributes</dependentValue><dependentValue>hwx-content-encoded-schema</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-name</name><displayName>Schema Name</displayName><description>Specifies the name of the schema to lookup in the Schema Registry property</description><defaultValue>${schema.name}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-version</name><displayName>Schema Version</displayName><description>Specifies the version of the schema to lookup in the Schema Registry. If not specified then the latest version of the schema will be retrieved.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-branch</name><displayName>Schema Branch</displayName><description>Specifies the name of the branch to use when looking up the schema in the Schema Registry property. If the chosen Schema Registry does not support branching, this value will be ignored.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-name</dependentValue></dependentValues></dependency></dependencies></property><property><name>schema-text</name><displayName>Schema Text</displayName><description>The text of an Avro-formatted Schema</description><defaultValue>${avro.schema}</defaultValue><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic><dependencies><dependency><propertyName>schema-access-strategy</propertyName><propertyDisplayName>Schema Access Strategy</propertyDisplayName><dependentValues><dependentValue>schema-text-property</dependentValue></dependentValues></dependency></dependencies></property><property><name>cache-size</name><displayName>Cache Size</displayName><description>Specifies how many Schemas should be cached</description><defaultValue>1000</defaultValue><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>compression-type</name><displayName>Compression Type</displayName><description>The type of compression for the file being written.</description><defaultValue>UNCOMPRESSED</defaultValue><allowableValues><allowableValue><displayName>UNCOMPRESSED</displayName><value>UNCOMPRESSED</value><description></description></allowableValue><allowableValue><displayName>SNAPPY</displayName><value>SNAPPY</value><description></description></allowableValue><allowableValue><displayName>GZIP</displayName><value>GZIP</value><description></description></allowableValue><allowableValue><displayName>LZO</displayName><value>LZO</value><description></description></allowableValue><allowableValue><displayName>BROTLI</displayName><value>BROTLI</value><description></description></allowableValue><allowableValue><displayName>LZ4</displayName><value>LZ4</value><description></description></allowableValue><allowableValue><displayName>ZSTD</displayName><value>ZSTD</value><description></description></allowableValue><allowableValue><displayName>LZ4_RAW</displayName><value>LZ4_RAW</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>row-group-size</name><displayName>Row Group Size</displayName><description>The row group size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>page-size</name><displayName>Page Size</displayName><description>The page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>dictionary-page-size</name><displayName>Dictionary Page Size</displayName><description>The dictionary page size used by the Parquet writer. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>max-padding-size</name><displayName>Max Padding Size</displayName><description>The maximum amount of padding that will be used to align row groups with blocks in the underlying filesystem. If the underlying filesystem is not a block filesystem like HDFS, this has no effect. The value is specified in the format of &lt;Data Size&gt; &lt;Data Unit&gt; where Data Unit is one of B, KB, MB, GB, TB.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>true</expressionLanguageSupported><expressionLanguageScope>FLOWFILE_ATTRIBUTES</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>enable-dictionary-encoding</name><displayName>Enable Dictionary Encoding</displayName><description>Specifies whether dictionary encoding should be enabled for the Parquet writer</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>enable-validation</name><displayName>Enable Validation</displayName><description>Specifies whether validation should be enabled for the Parquet writer</description><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>writer-version</name><displayName>Writer Version</displayName><description>Specifies the version used by Parquet writer</description><allowableValues><allowableValue><displayName>PARQUET_1_0</displayName><value>PARQUET_1_0</value><description></description></allowableValue><allowableValue><displayName>PARQUET_2_0</displayName><value>PARQUET_2_0</value><description></description></allowableValue></allowableValues><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>avro-write-old-list-structure</name><displayName>Avro Write Old List Structure</displayName><description>Specifies the value for 'parquet.avro.write-old-list-structure' in the underlying Parquet library</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>avro-add-list-element-records</name><displayName>Avro Add List Element Records</displayName><description>Specifies the value for 'parquet.avro.add-list-element-records' in the underlying Parquet library</description><defaultValue>true</defaultValue><allowableValues><allowableValue><displayName>true</displayName><value>true</value><description></description></allowableValue><allowableValue><displayName>false</displayName><value>false</value><description></description></allowableValue></allowableValues><required>true</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property><property><name>int96-fields</name><displayName>INT96 Fields</displayName><description>List of fields with full path that should be treated as INT96 timestamps.</description><required>false</required><sensitive>false</sensitive><expressionLanguageSupported>false</expressionLanguageSupported><expressionLanguageScope>NONE</expressionLanguageScope><dynamicallyModifiesClasspath>false</dynamicallyModifiesClasspath><dynamic>false</dynamic></property></properties><providedServiceAPIs><providedServiceAPI><className>org.apache.nifi.serialization.RecordSetWriterFactory</className><groupId>org.apache.nifi</groupId><artifactId>nifi-standard-services-api-nar</artifactId><version>2.0.0-SNAPSHOT</version></providedServiceAPI></providedServiceAPIs></extension></extensions></extensionManifest>